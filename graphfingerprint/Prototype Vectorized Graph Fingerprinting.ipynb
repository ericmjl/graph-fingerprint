{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wb import WeightsAndBiases\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from random import sample, choice\n",
    "from fingerprint_vect import GraphFingerprint\n",
    "from collections import defaultdict\n",
    "from autograd import grad\n",
    "from autograd.scipy.misc import logsumexp\n",
    "\n",
    "import autograd.numpy as np\n",
    "import networkx as nx\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_random_graph(nodes, n_edges, features_dict):\n",
    "    \"\"\"\n",
    "    Makes a randomly connected graph. \n",
    "    \"\"\"\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    for n in nodes:\n",
    "        G.add_node(n, features=features_dict[n])\n",
    "    \n",
    "    for i in range(n_edges):\n",
    "        u, v = sample(G.nodes(), 2)\n",
    "        G.add_edge(u, v)\n",
    "        \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 2, {}), (3, 4, {}), (3, 6, {}), (6, 8, {})]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features_dict will look like this:\n",
    "# {0: array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
    "#  1: array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
    "#  2: array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0]),\n",
    "#  3: array([0, 0, 0, 1, 0, 0, 0, 0, 0, 0]),\n",
    "#  4: array([0, 0, 0, 0, 1, 0, 0, 0, 0, 0]),\n",
    "#  5: array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n",
    "#  6: array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0]),\n",
    "#  7: array([0, 0, 0, 0, 0, 0, 0, 1, 0, 0]),\n",
    "#  8: array([0, 0, 0, 0, 0, 0, 0, 0, 1, 0]),\n",
    "#  9: array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1])}\n",
    "\n",
    "all_nodes = [i for i in range(10)]    \n",
    "lb = LabelBinarizer()\n",
    "features_dict = {i:lb.fit_transform(all_nodes)[i] for i in all_nodes}\n",
    "\n",
    "G = make_random_graph(sample(all_nodes, 6), 5, features_dict)\n",
    "G.edges(data=True)\n",
    "# G.nodes(data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wb = WeightsAndBiases(n_layers=2, shapes=(10, 20, 10))\n",
    "# wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# def score(G):\n",
    "#     \"\"\"\n",
    "#     The regressable score for each graph will be the sum of the \n",
    "#     (square root of each node + the sum of its neighbors.)\n",
    "#     \"\"\"\n",
    "#     sum_score = 0\n",
    "#     for n, d in G.nodes(data=True):\n",
    "#         sum_score += math.sqrt(n)\n",
    "        \n",
    "#         for nbr in G.neighbors(n):\n",
    "#             sum_score += nbr ** (1/3)\n",
    "#     return sum_score\n",
    "\n",
    "def score(G):\n",
    "    \"\"\"\n",
    "    The regressable score for each graph is the number of nodes\n",
    "    in the graph.\n",
    "    \"\"\"\n",
    "    return len(G.nodes())\n",
    "\n",
    "score(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G.nodes(data=True)[0][1]['features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10590253,  0.07747197,  0.06798611,  0.08309748,  0.14523769,\n",
       "         0.10324535,  0.09085766,  0.11327375,  0.14492305,  0.06800441]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(X, axis=0):\n",
    "    \"\"\"\n",
    "    The softmax function normalizes everything to between 0 and 1.\n",
    "    \"\"\"\n",
    "    return np.exp(X - logsumexp(X, axis=axis, keepdims=True))\n",
    "\n",
    "# test softmax:\n",
    "X = np.random.random((1,10))\n",
    "softmax(X, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09574597]\n",
      " [-0.05016848]\n",
      " [ 0.18500304]\n",
      " [-1.10497981]\n",
      " [ 0.27769682]]\n",
      "\n",
      "[[ 0.09574597]\n",
      " [-0.        ]\n",
      " [ 0.18500304]\n",
      " [-0.        ]\n",
      " [ 0.27769682]]\n"
     ]
    }
   ],
   "source": [
    "def relu(X):\n",
    "    \"\"\"\n",
    "    The ReLU - Rectified Linear Unit.\n",
    "    \"\"\"\n",
    "    return X * (X > 0)\n",
    "\n",
    "\n",
    "# test relu:\n",
    "X = np.random.normal(0, 1, size=(5, 1))\n",
    "print(X)\n",
    "print('')\n",
    "print(relu(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make 1000 random graphs.\n",
    "syngraphs = []\n",
    "for i in range(20):\n",
    "    n_nodes = choice([i for i in range(2, 10)])\n",
    "    n_edges = choice([i for i in range(1, n_nodes**2)])\n",
    "    \n",
    "    G = make_random_graph(sample(all_nodes, n_nodes), n_edges, features_dict)\n",
    "    syngraphs.append(G)\n",
    "    \n",
    "len(syngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a function that computes the feature matrix, and writes the\n",
    "# indices to the nodes of each graph.\n",
    "def stacked_node_activations(graphs):\n",
    "    \"\"\"\n",
    "    Note: this function should only be called for computing the\n",
    "    stacked node activations after initializing the graphs.\n",
    "    \n",
    "    Inputs:\n",
    "    =======\n",
    "    - graphs: (list) a list of graphs on which to stack their\n",
    "              feature vectors.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    curr_idx = 0\n",
    "    for g in graphs:\n",
    "        for n, d in g.nodes(data=True):\n",
    "            features.append(d['features'])\n",
    "            g.node[n]['idx'] = curr_idx\n",
    "            curr_idx += 1\n",
    "    return np.vstack(features)\n",
    "\n",
    "# test stacked_node_activations\n",
    "layers = dict()\n",
    "layers[0] = stacked_node_activations(syngraphs)\n",
    "layers[1] = stacked_node_activations(syngraphs)\n",
    "# layers[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function that gets the indices of each node's neighbors.\n",
    "def neighbor_indices(G, n):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    =======\n",
    "    - G: the graph to which the node belongs to.\n",
    "    - n: the node inside the graph G.\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    - indices: (list) a list of indices, which should (but is not\n",
    "               guaranteed to) correspond to a row in a large \n",
    "               stacked matrix of features.\n",
    "    \"\"\"\n",
    "    indices = []\n",
    "    for n in G.neighbors(n):\n",
    "        indices.append(G.node[n]['idx'])\n",
    "    return indices\n",
    "\n",
    "\n",
    "# test neighbor_indices\n",
    "nbr_idxs = neighbor_indices(syngraphs[0], syngraphs[0].nodes()[0])\n",
    "nbr_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function that sums each of the neighbors' activations for a\n",
    "# given node in a given graph.\n",
    "def neighbor_activations(G, n, activations_dict, layer):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    =======\n",
    "    - G: the graph to which the node belongs to.\n",
    "    - n: the node inside the graph G\n",
    "    - activations_dict: a dictionary that stores the node activations \n",
    "                        at each layer.\n",
    "    - layer: the layer at which to compute neighbor activations.\n",
    "    \"\"\"\n",
    "    nbr_indices = neighbor_indices(G, n)\n",
    "    return np.sum(activations_dict[layer][nbr_indices], axis=0)\n",
    "\n",
    "neighbor_activations(syngraphs[0], syngraphs[0].nodes()[0], layers, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write a function that stacks each of the nodes' neighbors\n",
    "# activations together into a large feature matrix.\n",
    "\n",
    "def stacked_neighbor_activations(graphs, activations_dict, layer):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    =======\n",
    "    - graphs: (list) a list of NetworkX graphs.\n",
    "    - activations_dict: (dict) a dictionary where keys are the layer\n",
    "                        number and values are the node activations.\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    - a stacked numpy array of neighbor activations\n",
    "    \"\"\"\n",
    "    nbr_activations = []\n",
    "    for g in graphs:\n",
    "        for n in g.nodes():\n",
    "            nbr_acts = neighbor_activations(g, n, activations_dict, layer)\n",
    "            nbr_activations.append(nbr_acts)\n",
    "    return np.vstack(nbr_activations)\n",
    "\n",
    "# stacked_neighbor_activations(syngraphs, layers, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'idx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-f98471cd7c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_acts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnbr_acts\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbiases\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyngraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-46-f98471cd7c40>\u001b[0m in \u001b[0;36mactivation\u001b[0;34m(activations_dict, wb, layer, graphs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mself_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_acts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'self_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnbr_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_neighbor_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mnbr_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_acts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'nbr_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-4bea9da03592>\u001b[0m in \u001b[0;36mstacked_neighbor_activations\u001b[0;34m(graphs, activations_dict, layer)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mnbr_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbor_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mnbr_activations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_acts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_activations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-677f377e9d0e>\u001b[0m in \u001b[0;36mneighbor_activations\u001b[0;34m(G, n, activations_dict, layer)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m-\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0mat\u001b[0m \u001b[0mwhich\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcompute\u001b[0m \u001b[0mneighbor\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mnbr_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbor_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnbr_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-78637bf466b0>\u001b[0m in \u001b[0;36mneighbor_indices\u001b[0;34m(G, n)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'idx'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'idx'"
     ]
    }
   ],
   "source": [
    "# Write a function that computes the next layers' activations.\n",
    "\n",
    "def activation(activations_dict, wb, layer, graphs):\n",
    "    \"\"\"\n",
    "    Inputs:\n",
    "    =======\n",
    "    - activations_dict: (dict) a dictionary where keys are the layer\n",
    "                        number and values are the node activations.\n",
    "    - wb: (wb.WeightsAndBiases) the WB class storing the weights and\n",
    "          biases.\n",
    "    - layer: (int) the layer for which to compute the activations.    \n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    - a stacked numpy array of activations, which can be assigned to\n",
    "      the activations_dict's next layer if desired (actually it\n",
    "      should be).\n",
    "    \"\"\"\n",
    "    \n",
    "    self_acts = activations_dict[layer]\n",
    "    self_acts = np.dot(self_acts, wb[layer]['self_weights'])\n",
    "\n",
    "    nbr_acts = stacked_neighbor_activations(graphs, activations_dict, layer)\n",
    "    nbr_acts = np.dot(nbr_acts, wb[layer]['nbr_weights'])\n",
    "    \n",
    "    biases = wb[layer]['biases']\n",
    "    \n",
    "    return relu(self_acts + nbr_acts + biases)\n",
    "\n",
    "print(activation(layers, wb, 0, syngraphs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118, 20)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = np.dot(stacked_neighbor_activations(syngraphs, layers, 0), wb[0]['nbr_weights']) + wb[0]['biases']\n",
    "act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a function that gets the indices of all of the nodes in the\n",
    "# graph.\n",
    "def graph_indices(g):\n",
    "    \"\"\"\n",
    "    Returns the row indices of each of the nodes in the graphs.\n",
    "    \"\"\"\n",
    "    return [d['idx'] for _, d in g.nodes(data=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, 1, 1, 1, 0, 1, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 1, 1, 1],\n",
       "       [0, 0, 1, 1, 1, 0, 1, 1, 1, 1],\n",
       "       [0, 0, 1, 0, 1, 0, 1, 1, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 1, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 0, 0, 1, 0, 1, 0, 1],\n",
       "       [0, 0, 0, 1, 0, 1, 0, 1, 0, 0],\n",
       "       [1, 1, 1, 0, 1, 1, 1, 0, 1, 1],\n",
       "       [1, 1, 1, 0, 1, 1, 0, 1, 1, 1],\n",
       "       [1, 1, 1, 1, 1, 1, 1, 0, 1, 1],\n",
       "       [0, 1, 0, 0, 0, 1, 0, 1, 0, 1],\n",
       "       [1, 1, 1, 0, 0, 1, 0, 1, 1, 0],\n",
       "       [1, 1, 0, 1, 0, 0, 1, 1, 1, 1],\n",
       "       [0, 1, 1, 1, 0, 1, 1, 1, 1, 1],\n",
       "       [1, 1, 1, 0, 1, 1, 1, 1, 1, 0]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function that makes the fingerprint used for predictions.\n",
    "def fingerprint(activations_dict, graphs):\n",
    "    \"\"\"\n",
    "    Computes the final layer fingerprint for each graph.\n",
    "    \n",
    "    Inputs:\n",
    "    =======\n",
    "    - activations_dict: (dict) a dictionary where keys are the layer\n",
    "                        number and values are the node activations.\n",
    "    - graphs: a list of graphs for which to compute the fingerprints.\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    - a stacked numpy array of fingerprints, of length len(graphs).\n",
    "    \"\"\"\n",
    "    top_layer = max(activations_dict.keys())\n",
    "    fingerprints = []\n",
    "    for g in graphs:\n",
    "        idxs = graph_indices(g)\n",
    "        fp = np.sum(activations_dict[top_layer][idxs], axis=0)\n",
    "        fingerprints.append(fp)\n",
    "    \n",
    "    return relu(np.vstack(fingerprints))\n",
    "\n",
    "# test fingerprint function\n",
    "fingerprint(layers, syngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.4140944 ],\n",
       "       [-0.80994935],\n",
       "       [-0.05438736],\n",
       "       [-0.08457893],\n",
       "       [-0.03971847],\n",
       "       [-0.35550169],\n",
       "       [-0.15989237],\n",
       "       [-0.3462132 ],\n",
       "       [-0.02066551],\n",
       "       [-0.02535193],\n",
       "       [-0.06567089],\n",
       "       [-0.03222333],\n",
       "       [-0.22609366],\n",
       "       [-0.44758711],\n",
       "       [-0.18338839],\n",
       "       [-0.04373497],\n",
       "       [-0.18453728],\n",
       "       [-0.33261526],\n",
       "       [-0.21751378],\n",
       "       [-0.33543044]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function that makes the forward pass predictions.\n",
    "def predict(wb_vect, wb_unflattener, activations_dict, graphs):\n",
    "    \"\"\"\n",
    "    Makes predictions.\n",
    "    \n",
    "    Change this function for each new learning problem.\n",
    "    \n",
    "    Inputs:\n",
    "    =======\n",
    "    - wb_vect: (WeightsAndBiases.vect)\n",
    "    - wb_unfalttener (WeightsAndBiases.unflattener)\n",
    "    - activations_dict: (dict) a dictionary where keys are the layer\n",
    "                        number and values are the node activations.\n",
    "    - graphs: a list of graphs for which to compute the fingerprints.\n",
    "    \n",
    "    Returns:\n",
    "    ========\n",
    "    - a numpy array of predictions, of length len(graphs).\n",
    "    \"\"\"\n",
    "    \n",
    "    wb = wb_unflattener(wb_vect)\n",
    "    for k in sorted(wb.keys()):\n",
    "        activations_dict[k + 1] = activation(activations_dict, wb, k, graphs)\n",
    "        # print(activations_dict[k])\n",
    "    \n",
    "    top_layer = max(wb.keys())\n",
    "    \n",
    "    fps = fingerprint(layers, graphs)\n",
    "    \n",
    "    return np.dot(fps, wb[top_layer]['linweights'])\n",
    "\n",
    "predict(*wb.flattened(), layers, syngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77174070288183994"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function that computes the training loss.\n",
    "def train_loss(wb_vect, wb_unflattener, activations_dict, graphs):\n",
    "    \"\"\"\n",
    "    Computes the training loss as mean squared error.\n",
    "    \n",
    "    Inputs:\n",
    "    =======\n",
    "    - wb_vect: (WeightsAndBiases.vect)\n",
    "    - wb_unfalttener (WeightsAndBiases.unflattener)\n",
    "    - activations_dict: (dict) a dictionary where keys are the layer\n",
    "                        number and values are the node activations.\n",
    "    - graphs: a list of graphs for which to compute the fingerprints.\n",
    "\n",
    "    Returns:\n",
    "    ========\n",
    "    - mean squared error.\n",
    "    \"\"\"\n",
    "    \n",
    "    scores = np.array([score(g) for g in graphs]).reshape((len(graphs), 1))\n",
    "    # print(scores)\n",
    "    preds = predict(wb_vect, wb_unflattener, activations_dict, graphs)\n",
    "    # print(preds)\n",
    "    return np.sum(np.power(preds - scores, 2)) / len(scores)\n",
    "\n",
    "train_loss(wb.vect, wb.unflattener, layers, syngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.00000000e+00,   4.36545916e-02,   3.01206013e-02, ...,\n",
       "        -2.99765891e-05,   6.78054181e-02,   0.00000000e+00])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradfunc = grad(train_loss, argnum=0)\n",
    "gradfunc(wb.vect, wb.unflattener, layers, syngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.67276760589\n",
      "Epoch Time: 0.15809106826782227\n",
      "1\n",
      "0.519709997502\n",
      "Epoch Time: 0.17552399635314941\n",
      "2\n",
      "0.365243994256\n",
      "Epoch Time: 0.14338183403015137\n",
      "3\n",
      "0.249816520583\n",
      "Epoch Time: 0.15077614784240723\n",
      "4\n",
      "0.189969966201\n",
      "Epoch Time: 0.1405642032623291\n",
      "5\n",
      "0.179175168473\n",
      "Epoch Time: 0.2888529300689697\n",
      "6\n",
      "0.202457764917\n",
      "Epoch Time: 0.25779199600219727\n",
      "7\n",
      "0.240191970356\n",
      "Epoch Time: 0.16279006004333496\n",
      "8\n",
      "0.275522609796\n",
      "Epoch Time: 0.17266297340393066\n",
      "9\n",
      "0.296764999479\n",
      "Epoch Time: 0.23338699340820312\n",
      "10\n",
      "0.298641869262\n",
      "Epoch Time: 0.14048004150390625\n",
      "11\n",
      "0.281555614684\n",
      "Epoch Time: 0.14654302597045898\n",
      "12\n",
      "0.250107867914\n",
      "Epoch Time: 0.1505289077758789\n",
      "13\n",
      "0.211169974916\n",
      "Epoch Time: 0.19708895683288574\n",
      "14\n",
      "0.171896379056\n",
      "Epoch Time: 0.2993190288543701\n",
      "15\n",
      "0.1382448387\n",
      "Epoch Time: 0.1716620922088623\n",
      "16\n",
      "0.113899536158\n",
      "Epoch Time: 0.1766970157623291\n",
      "17\n",
      "0.100432243778\n",
      "Epoch Time: 0.12554121017456055\n",
      "18\n",
      "0.0965960794042\n",
      "Epoch Time: 0.16973400115966797\n",
      "19\n",
      "0.100463748826\n",
      "Epoch Time: 0.12432217597961426\n",
      "20\n",
      "0.108049144955\n",
      "Epoch Time: 0.0913701057434082\n",
      "21\n",
      "0.11540884078\n",
      "Epoch Time: 0.09949517250061035\n",
      "22\n",
      "0.119570988513\n",
      "Epoch Time: 0.08339095115661621\n",
      "23\n",
      "0.119011475604\n",
      "Epoch Time: 0.10935187339782715\n",
      "24\n",
      "0.113759002025\n",
      "Epoch Time: 0.08563804626464844\n",
      "25\n",
      "0.104929668427\n",
      "Epoch Time: 0.09794497489929199\n",
      "26\n",
      "0.0943072461764\n",
      "Epoch Time: 0.1364271640777588\n",
      "27\n",
      "0.0837504001197\n",
      "Epoch Time: 0.11782717704772949\n",
      "28\n",
      "0.0747370492615\n",
      "Epoch Time: 0.19859099388122559\n",
      "29\n",
      "0.0681957034625\n",
      "Epoch Time: 0.09680795669555664\n",
      "30\n",
      "0.0642548247157\n",
      "Epoch Time: 0.09877705574035645\n",
      "31\n",
      "0.0625307745733\n",
      "Epoch Time: 0.1034848690032959\n",
      "32\n",
      "0.0623600439961\n",
      "Epoch Time: 0.07760405540466309\n",
      "33\n",
      "0.0629591866183\n",
      "Epoch Time: 0.10930895805358887\n",
      "34\n",
      "0.0636119086017\n",
      "Epoch Time: 0.09763002395629883\n",
      "35\n",
      "0.0637714366822\n",
      "Epoch Time: 0.08770084381103516\n",
      "36\n",
      "0.0631239511907\n",
      "Epoch Time: 0.08395099639892578\n",
      "37\n",
      "0.0616098561329\n",
      "Epoch Time: 0.13645005226135254\n",
      "38\n",
      "0.059354392362\n",
      "Epoch Time: 0.1989579200744629\n",
      "39\n",
      "0.0566002354098\n",
      "Epoch Time: 0.12883400917053223\n",
      "40\n",
      "0.0536422459885\n",
      "Epoch Time: 0.16208505630493164\n",
      "41\n",
      "0.0507828101667\n",
      "Epoch Time: 0.11619997024536133\n",
      "42\n",
      "0.0482654779948\n",
      "Epoch Time: 0.09464287757873535\n",
      "43\n",
      "0.0462262510754\n",
      "Epoch Time: 0.08729696273803711\n",
      "44\n",
      "0.0447086863827\n",
      "Epoch Time: 0.11520695686340332\n",
      "45\n",
      "0.043665500671\n",
      "Epoch Time: 0.08374595642089844\n",
      "46\n",
      "0.0428872137519\n",
      "Epoch Time: 0.08515405654907227\n",
      "47\n",
      "0.0422829034787\n",
      "Epoch Time: 0.15094804763793945\n",
      "48\n",
      "0.0417895022015\n",
      "Epoch Time: 0.2170419692993164\n",
      "49\n",
      "0.0412820874714\n",
      "Epoch Time: 0.12810897827148438\n",
      "50\n",
      "0.0406590542302\n",
      "Epoch Time: 0.20282387733459473\n",
      "51\n",
      "0.0398781433166\n",
      "Epoch Time: 0.141035795211792\n",
      "52\n",
      "0.0389411456534\n",
      "Epoch Time: 0.10340404510498047\n",
      "53\n",
      "0.0378894612559\n",
      "Epoch Time: 0.12001299858093262\n",
      "54\n",
      "0.0367838212329\n",
      "Epoch Time: 0.0860891342163086\n",
      "55\n",
      "0.0356907861948\n",
      "Epoch Time: 0.17188310623168945\n",
      "56\n",
      "0.0346632350332\n",
      "Epoch Time: 0.18347811698913574\n",
      "57\n",
      "0.0337394791134\n",
      "Epoch Time: 0.20557188987731934\n",
      "58\n",
      "0.0329363442973\n",
      "Epoch Time: 0.2087240219116211\n",
      "59\n",
      "0.0322500644289\n",
      "Epoch Time: 0.14825010299682617\n",
      "60\n",
      "0.0316617086732\n",
      "Epoch Time: 0.12659907341003418\n",
      "61\n",
      "0.0311431121684\n",
      "Epoch Time: 0.15209507942199707\n",
      "62\n",
      "0.0306634252321\n",
      "Epoch Time: 0.21123409271240234\n",
      "63\n",
      "0.0301948375653\n",
      "Epoch Time: 0.14742088317871094\n",
      "64\n",
      "0.0297165677404\n",
      "Epoch Time: 0.11933302879333496\n",
      "65\n",
      "0.0292176307625\n",
      "Epoch Time: 0.08783602714538574\n",
      "66\n",
      "0.0286955813619\n",
      "Epoch Time: 0.08727002143859863\n",
      "67\n",
      "0.0281556101859\n",
      "Epoch Time: 0.12844514846801758\n",
      "68\n",
      "0.0276078313723\n",
      "Epoch Time: 0.3142120838165283\n",
      "69\n",
      "0.0270644669798\n",
      "Epoch Time: 0.19463491439819336\n",
      "70\n",
      "0.0265370905064\n",
      "Epoch Time: 0.16424918174743652\n",
      "71\n",
      "0.0260040235816\n",
      "Epoch Time: 0.17171096801757812\n",
      "72\n",
      "0.025495756376\n",
      "Epoch Time: 0.12290501594543457\n",
      "73\n",
      "0.0250200682179\n",
      "Epoch Time: 0.13110113143920898\n",
      "74\n",
      "0.0245763291716\n",
      "Epoch Time: 0.09866094589233398\n",
      "75\n",
      "0.0241604433213\n",
      "Epoch Time: 0.1123499870300293\n",
      "76\n",
      "0.0237661477999\n",
      "Epoch Time: 0.1517031192779541\n",
      "77\n",
      "0.0233864873758\n",
      "Epoch Time: 0.29996204376220703\n",
      "78\n",
      "0.023015121729\n",
      "Epoch Time: 0.1734180450439453\n",
      "79\n",
      "0.0226472767675\n",
      "Epoch Time: 0.20694899559020996\n",
      "80\n",
      "0.0222802319695\n",
      "Epoch Time: 0.23494315147399902\n",
      "81\n",
      "0.0219132577066\n",
      "Epoch Time: 0.17871308326721191\n",
      "82\n",
      "0.0215474817406\n",
      "Epoch Time: 0.1515040397644043\n",
      "83\n",
      "0.0211852015127\n",
      "Epoch Time: 0.1388230323791504\n",
      "84\n",
      "0.0208297055611\n",
      "Epoch Time: 0.09818387031555176\n",
      "85\n",
      "0.0204868726028\n",
      "Epoch Time: 0.11666607856750488\n",
      "86\n",
      "0.0201548669972\n",
      "Epoch Time: 0.09231090545654297\n",
      "87\n",
      "0.0198352321883\n",
      "Epoch Time: 0.19968199729919434\n",
      "88\n",
      "0.0195276137343\n",
      "Epoch Time: 0.1350541114807129\n",
      "89\n",
      "0.0192313974454\n",
      "Epoch Time: 0.12230086326599121\n",
      "90\n",
      "0.0189483664657\n",
      "Epoch Time: 0.13256287574768066\n",
      "91\n",
      "0.0186759696027\n",
      "Epoch Time: 0.14299392700195312\n",
      "92\n",
      "0.0184108064028\n",
      "Epoch Time: 0.12851405143737793\n",
      "93\n",
      "0.0181515451804\n",
      "Epoch Time: 0.11595797538757324\n",
      "94\n",
      "0.0178972320437\n",
      "Epoch Time: 0.11960005760192871\n",
      "95\n",
      "0.0176473296043\n",
      "Epoch Time: 0.10412788391113281\n",
      "96\n",
      "0.017401674398\n",
      "Epoch Time: 0.0810401439666748\n",
      "97\n",
      "0.0171604142699\n",
      "Epoch Time: 0.24204802513122559\n",
      "98\n",
      "0.0169236301451\n",
      "Epoch Time: 0.20845389366149902\n",
      "99\n",
      "0.0166915759697\n",
      "Epoch Time: 0.17960882186889648\n",
      "100\n",
      "0.0164637186594\n",
      "Epoch Time: 0.16512084007263184\n",
      "101\n",
      "0.0162402521173\n",
      "Epoch Time: 0.11943697929382324\n",
      "102\n",
      "0.0160222077873\n",
      "Epoch Time: 0.16980290412902832\n",
      "103\n",
      "0.0158094729559\n",
      "Epoch Time: 0.1951150894165039\n",
      "104\n",
      "0.015601803286\n",
      "Epoch Time: 0.15648889541625977\n",
      "105\n",
      "0.015398870775\n",
      "Epoch Time: 0.08746099472045898\n",
      "106\n",
      "0.0152003167325\n",
      "Epoch Time: 0.0904397964477539\n",
      "107\n",
      "0.0150068775653\n",
      "Epoch Time: 0.17812013626098633\n",
      "108\n",
      "0.0148180157911\n",
      "Epoch Time: 0.1676790714263916\n",
      "109\n",
      "0.0146333064458\n",
      "Epoch Time: 0.16890192031860352\n",
      "110\n",
      "0.0144521633072\n",
      "Epoch Time: 0.1773219108581543\n",
      "111\n",
      "0.0142745373198\n",
      "Epoch Time: 0.17998600006103516\n",
      "112\n",
      "0.0141003508494\n",
      "Epoch Time: 0.26571106910705566\n",
      "113\n",
      "0.0139295884792\n",
      "Epoch Time: 0.1656949520111084\n",
      "114\n",
      "0.0137622265502\n",
      "Epoch Time: 0.203322172164917\n",
      "115\n",
      "0.0135982572865\n",
      "Epoch Time: 0.19545817375183105\n",
      "116\n",
      "0.0134376544254\n",
      "Epoch Time: 0.14963293075561523\n",
      "117\n",
      "0.0132803642991\n",
      "Epoch Time: 0.3542819023132324\n",
      "118\n",
      "0.0131263070962\n",
      "Epoch Time: 0.14770293235778809\n",
      "119\n",
      "0.0129753841194\n",
      "Epoch Time: 0.2656288146972656\n",
      "120\n",
      "0.012827264676\n",
      "Epoch Time: 0.18648099899291992\n",
      "121\n",
      "0.012681817288\n",
      "Epoch Time: 0.17218303680419922\n",
      "122\n",
      "0.0125391113949\n",
      "Epoch Time: 0.14994096755981445\n",
      "123\n",
      "0.0123990425518\n",
      "Epoch Time: 0.15392088890075684\n",
      "124\n",
      "0.0122615219394\n",
      "Epoch Time: 0.14308404922485352\n",
      "125\n",
      "0.0121264773663\n",
      "Epoch Time: 0.2529280185699463\n",
      "126\n",
      "0.0119938516953\n",
      "Epoch Time: 0.37139391899108887\n",
      "127\n",
      "0.0118635994188\n",
      "Epoch Time: 0.1851511001586914\n",
      "128\n",
      "0.0117356776818\n",
      "Epoch Time: 0.24257206916809082\n",
      "129\n",
      "0.0116100537828\n",
      "Epoch Time: 0.3074629306793213\n",
      "130\n",
      "0.0114865240618\n",
      "Epoch Time: 0.20826411247253418\n",
      "131\n",
      "0.0113651039806\n",
      "Epoch Time: 0.16225004196166992\n",
      "132\n",
      "0.0112460463196\n",
      "Epoch Time: 0.17823004722595215\n",
      "133\n",
      "0.0111293234149\n",
      "Epoch Time: 0.21312212944030762\n",
      "134\n",
      "0.0110146806006\n",
      "Epoch Time: 0.17337298393249512\n",
      "135\n",
      "0.0109020623867\n",
      "Epoch Time: 0.17001104354858398\n",
      "136\n",
      "0.0107914138018\n",
      "Epoch Time: 0.2066490650177002\n",
      "137\n",
      "0.010682679669\n",
      "Epoch Time: 0.12774896621704102\n",
      "138\n",
      "0.0105765165672\n",
      "Epoch Time: 0.1224219799041748\n",
      "139\n",
      "0.010474609562\n",
      "Epoch Time: 0.10490989685058594\n",
      "140\n",
      "0.0103748897019\n",
      "Epoch Time: 0.12877893447875977\n",
      "141\n",
      "0.0102769865794\n",
      "Epoch Time: 0.11943411827087402\n",
      "142\n",
      "0.0101808378368\n",
      "Epoch Time: 0.1585099697113037\n",
      "143\n",
      "0.0100863973595\n",
      "Epoch Time: 0.16044306755065918\n",
      "144\n",
      "0.00999361697477\n",
      "Epoch Time: 0.14638590812683105\n",
      "145\n",
      "0.00990245177087\n",
      "Epoch Time: 0.16121196746826172\n",
      "146\n",
      "0.00981285940282\n",
      "Epoch Time: 0.2007291316986084\n",
      "147\n",
      "0.00972479947817\n",
      "Epoch Time: 0.16707801818847656\n",
      "148\n",
      "0.00963823306817\n",
      "Epoch Time: 0.12162494659423828\n",
      "149\n",
      "0.00955312237853\n",
      "Epoch Time: 0.1602339744567871\n",
      "150\n",
      "0.00946943057904\n",
      "Epoch Time: 0.15663480758666992\n",
      "151\n",
      "0.00938681338686\n",
      "Epoch Time: 0.1436450481414795\n",
      "152\n",
      "0.00930547965715\n",
      "Epoch Time: 0.10521912574768066\n",
      "153\n",
      "0.00922531599515\n",
      "Epoch Time: 0.12975788116455078\n",
      "154\n",
      "0.00914637099674\n",
      "Epoch Time: 0.12823891639709473\n",
      "155\n",
      "0.0090686376313\n",
      "Epoch Time: 0.13267898559570312\n",
      "156\n",
      "0.00899209132262\n",
      "Epoch Time: 0.21919679641723633\n",
      "157\n",
      "0.00891670866121\n",
      "Epoch Time: 0.12835407257080078\n",
      "158\n",
      "0.00884246721179\n",
      "Epoch Time: 0.2546579837799072\n",
      "159\n",
      "0.00876934528852\n",
      "Epoch Time: 0.14373016357421875\n",
      "160\n",
      "0.00869743666442\n",
      "Epoch Time: 0.15531301498413086\n",
      "161\n",
      "0.00862766946125\n",
      "Epoch Time: 0.17506098747253418\n",
      "162\n",
      "0.0085589927266\n",
      "Epoch Time: 0.16774988174438477\n",
      "163\n",
      "0.00849142092924\n",
      "Epoch Time: 0.15909695625305176\n",
      "164\n",
      "0.00842497603245\n",
      "Epoch Time: 0.1340959072113037\n",
      "165\n",
      "0.00835954177823\n",
      "Epoch Time: 0.17125296592712402\n",
      "166\n",
      "0.00829509295534\n",
      "Epoch Time: 0.23639392852783203\n",
      "167\n",
      "0.00823160513496\n",
      "Epoch Time: 0.1316661834716797\n",
      "168\n",
      "0.00816905497542\n",
      "Epoch Time: 0.14069509506225586\n",
      "169\n",
      "0.00810742065991\n",
      "Epoch Time: 0.14436602592468262\n",
      "170\n",
      "0.00804667973131\n",
      "Epoch Time: 0.1110529899597168\n",
      "171\n",
      "0.00798681176122\n",
      "Epoch Time: 0.11226511001586914\n",
      "172\n",
      "0.00792779736529\n",
      "Epoch Time: 0.09699201583862305\n",
      "173\n",
      "0.00786961812812\n",
      "Epoch Time: 0.1319270133972168\n",
      "174\n",
      "0.00781225649708\n",
      "Epoch Time: 0.1273939609527588\n",
      "175\n",
      "0.0077556956612\n",
      "Epoch Time: 0.26929688453674316\n",
      "176\n",
      "0.00769991943115\n",
      "Epoch Time: 0.15114212036132812\n",
      "177\n",
      "0.00764491213349\n",
      "Epoch Time: 0.15407705307006836\n",
      "178\n",
      "0.00759065852826\n",
      "Epoch Time: 0.12313389778137207\n",
      "179\n",
      "0.00753714375365\n",
      "Epoch Time: 0.12388396263122559\n",
      "180\n",
      "0.00748435329713\n",
      "Epoch Time: 0.13428401947021484\n",
      "181\n",
      "0.00743227298849\n",
      "Epoch Time: 0.12202000617980957\n",
      "182\n",
      "0.00738088900813\n",
      "Epoch Time: 0.1233060359954834\n",
      "183\n",
      "0.00733019080919\n",
      "Epoch Time: 0.10522317886352539\n",
      "184\n",
      "0.00728017322975\n",
      "Epoch Time: 0.11958694458007812\n",
      "185\n",
      "0.00723081388635\n",
      "Epoch Time: 0.1788480281829834\n",
      "186\n",
      "0.00718210026439\n",
      "Epoch Time: 0.15226411819458008\n",
      "187\n",
      "0.0071340202557\n",
      "Epoch Time: 0.1587531566619873\n",
      "188\n",
      "0.00708656219322\n",
      "Epoch Time: 0.13465619087219238\n",
      "189\n",
      "0.00703971477843\n",
      "Epoch Time: 0.11770105361938477\n",
      "190\n",
      "0.0069934669826\n",
      "Epoch Time: 0.12220406532287598\n",
      "191\n",
      "0.0069476857064\n",
      "Epoch Time: 0.1321578025817871\n",
      "192\n",
      "0.00690244341401\n",
      "Epoch Time: 0.12490105628967285\n",
      "193\n",
      "0.00685775635021\n",
      "Epoch Time: 0.10334086418151855\n",
      "194\n",
      "0.00681361657944\n",
      "Epoch Time: 0.12047815322875977\n",
      "195\n",
      "0.00677001618953\n",
      "Epoch Time: 0.1936509609222412\n",
      "196\n",
      "0.0067269473045\n",
      "Epoch Time: 0.1417231559753418\n",
      "197\n",
      "0.00668440209738\n",
      "Epoch Time: 0.13784503936767578\n",
      "198\n",
      "0.00664237280267\n",
      "Epoch Time: 0.13803410530090332\n",
      "199\n",
      "0.00660085172757\n",
      "Epoch Time: 0.14908194541931152\n"
     ]
    }
   ],
   "source": [
    "def sgd(grad, wb_vect, wb_unflattener, activations_dict, graphs, callback=None, num_iters=200, step_size=0.1, mass=0.9):\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent with momentum.\n",
    "    \"\"\"\n",
    "    from time import time\n",
    "    velocity = np.zeros(len(wb_vect))\n",
    "    for i in range(num_iters):\n",
    "        start = time()\n",
    "        print(i)\n",
    "        g = grad(wb_vect, wb_unflattener, activations_dict, graphs)\n",
    "\n",
    "        velocity = mass * velocity - (1.0 - mass) * g\n",
    "        wb_vect += step_size * velocity\n",
    "        # print(wb_vect)\n",
    "        print(train_loss(wb_vect, wb_unflattener, activations_dict, graphs))\n",
    "        end = time()\n",
    "        print('Epoch Time: {0}'.format(end - start))\n",
    "    return wb_vect, wb_unflattener\n",
    "\n",
    "wb_vect, wb_unflattener = sgd(gradfunc, wb.vect, wb.unflattener, layers, syngraphs, num_iters=200, step_size=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.043996281002482249"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss(wb_vect, wb.unflattener, layers, syngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.1676535 ],\n",
       "       [ 0.03242438],\n",
       "       [-0.00748493],\n",
       "       [ 0.66346477],\n",
       "       [ 0.27239111],\n",
       "       [-0.09952596],\n",
       "       [ 0.4714696 ],\n",
       "       [ 0.07962087],\n",
       "       [ 0.28633275],\n",
       "       [-0.04745121]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wb.unflattener(wb.vect)[2]['linweights']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = [score(g) for g in syngraphs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = predict(wb_vect, wb.unflattener, layers, syngraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, array([ 2.06262481])),\n",
       " (6, array([ 5.92384939])),\n",
       " (9, array([ 9.15106495])),\n",
       " (5, array([ 5.39515665])),\n",
       " (7, array([ 7.002901])),\n",
       " (2, array([ 2.00901536])),\n",
       " (9, array([ 8.53653948])),\n",
       " (8, array([ 7.91750888])),\n",
       " (8, array([ 7.99536548])),\n",
       " (4, array([ 4.17193318]))]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in zip(scores, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 1, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_graphs = [make_random_graph(sample(all_nodes, 4), 5, features_dict) for i in range(100)]\n",
    "# predict(wb_vect, wb.unflattener, layers, new_graphs)\n",
    "new_graphs[0].nodes(data=True)\n",
    "\n",
    "stacked_node_activations(new_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 62 is out of bounds for axis 0 with size 60",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-f82372ec046b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwb_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflattener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_graphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-19-38ccf9e2efb0>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(wb_vect, wb_unflattener, activations_dict, graphs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mwb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb_unflattener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwb_vect\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mactivations_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;31m# print(activations_dict[k])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-32815cd899ec>\u001b[0m in \u001b[0;36mactivation\u001b[0;34m(activations_dict, wb, layer, graphs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mself_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself_acts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'self_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mnbr_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstacked_neighbor_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;31m# print('nbr_dtype: {0}....... wb_dtype: {1}'.format(nbr_acts.dtype, wb[layer]['nbr_weights'].dtype))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# print('nbr_act type: {0}'.format(type(nbr_acts)))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-4bea9da03592>\u001b[0m in \u001b[0;36mstacked_neighbor_activations\u001b[0;34m(graphs, activations_dict, layer)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraphs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mnbr_acts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbor_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m             \u001b[0mnbr_activations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_acts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbr_activations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-677f377e9d0e>\u001b[0m in \u001b[0;36mneighbor_activations\u001b[0;34m(G, n, activations_dict, layer)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m     \u001b[0mnbr_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneighbor_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnbr_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mneighbor_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyngraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msyngraphs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 62 is out of bounds for axis 0 with size 60"
     ]
    }
   ],
   "source": [
    "predict(wb_vect, wb.unflattener, layers, new_graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
