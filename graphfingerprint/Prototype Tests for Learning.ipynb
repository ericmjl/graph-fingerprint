{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fingerprint import GraphFingerprint\n",
    "from wb import WeightsAndBiases\n",
    "from itertools import combinations\n",
    "from random import choice, sample\n",
    "from numpy.random import permutation\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.cross_validation import train_test_split, ShuffleSplit, cross_val_score\n",
    "from autograd import grad\n",
    "from time import time\n",
    "\n",
    "import autograd.numpy as np\n",
    "import networkx as nx\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import jit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "shapes = dict()\n",
    "shapes[0] = 10\n",
    "shapes[1] = 10\n",
    "shapes[2] = 10\n",
    "wb = WeightsAndBiases(2, shapes)\n",
    "# wb[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def rnd():\n",
    "    return np.random.binomial(1, 0.2, size=10)\n",
    "\n",
    "all_letters = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "\n",
    "\n",
    "def make_nodes_with_features():\n",
    "    features = dict()\n",
    "    for letter in all_letters:\n",
    "        features[letter] = rnd()\n",
    "\n",
    "    return features\n",
    "\n",
    "node_features = make_nodes_with_features()\n",
    "\n",
    "\n",
    "def make_synthetic_graphs(num_graphs, features):\n",
    "    num_nodes = [i for i in range(2, len(all_letters) + 1)]\n",
    "\n",
    "    # Make the synthetic graphs.\n",
    "    syngraphs = []  # the synthetic graphs\n",
    "    for i in range(num_graphs):\n",
    "        # add in nodes\n",
    "        n_nodes = choice(num_nodes)\n",
    "        letters = sample(all_letters, n_nodes)\n",
    "        G = nx.Graph()\n",
    "        for letter in letters:\n",
    "            G.add_node(letter, features=features[letter])\n",
    "\n",
    "        # add in edges\n",
    "        n_nodes = len(G.nodes())\n",
    "        num_edges = choice(range(1, int(n_nodes**2 / 2 - n_nodes / 2 + 1)))\n",
    "        edges = sample([i for i in combinations(G.nodes(), 2)], num_edges)\n",
    "        for u, v in edges:\n",
    "            G.add_edge(u, v)\n",
    "        syngraphs.append(G)\n",
    "    return syngraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "syngraphs = make_synthetic_graphs(1000, node_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(syngraphs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up a learning scenario where..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fingerprints = np.zeros((len(syngraphs), 10))\n",
    "\n",
    "for i, g in enumerate(syngraphs):\n",
    "    gfp = GraphFingerprint(g, 2, shapes)\n",
    "    fp = gfp.compute_fingerprint(wb.vect, wb.unflattener)\n",
    "    fingerprints[i] = fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 5,\n",
       " 6,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 3,\n",
       " 7,\n",
       " 5,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 3,\n",
       " 5,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 3,\n",
       " 2,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 7,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 2,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 7,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 4,\n",
       " 7,\n",
       " 7,\n",
       " 4,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 3,\n",
       " 6,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 3,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 6,\n",
       " 6,\n",
       " 7,\n",
       " 7,\n",
       " 6,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 3,\n",
       " 6,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 2,\n",
       " 5,\n",
       " 5,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 5,\n",
       " 2,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 7,\n",
       " 2,\n",
       " 2,\n",
       " 6,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 4,\n",
       " 4,\n",
       " 4,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 3,\n",
       " 2,\n",
       " 6,\n",
       " 2,\n",
       " 3,\n",
       " 5,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 5,\n",
       " 7,\n",
       " 5,\n",
       " 7,\n",
       " 6,\n",
       " 4,\n",
       " 4,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 2,\n",
       " 4,\n",
       " 3,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 7,\n",
       " 4,\n",
       " 3,\n",
       " 3,\n",
       " 4,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 6,\n",
       " 3,\n",
       " 5,\n",
       " 6,\n",
       " 2]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "X = pd.DataFrame(np.array(fingerprints))\n",
    "Y = [len(g.nodes()) for g in syngraphs]\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A simple test - the weights are random, so given the random weights, what is the prediction accuracy using\n",
    "# random forest?\n",
    "\n",
    "cv = ShuffleSplit(n=len(X), n_iter=10)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 5.9  3.   3.   2.   5.9  4.   5.   6.2  2.   6.1  3.   5.4  6.   2.9  6.9\n",
      "  2.   5.3  3.   7.   7.   4.   2.   2.   6.6  4.   2.   5.   2.   2.   4.6\n",
      "  7.   3.   5.   5.2  3.9  5.1  6.6  7.   2.   3.   7.   6.6  5.   5.6  6.\n",
      "  5.9  6.4  4.1  6.   6.7  4.   2.   2.   6.   6.5  7.   5.3  7.   3.   3.\n",
      "  2.   4.   5.   6.   6.   3.   5.   5.2  3.   4.   5.1  3.1  3.   3.1  2.\n",
      "  6.9  4.2  3.   5.2  6.7  5.   6.   6.3  2.   3.   4.   4.   5.   7.   5.8\n",
      "  4.   3.   6.9  2.9  3.   3.   5.   5.   6.9  2.   3.   2.   3.   3.   4.\n",
      "  5.2  3.   2.   4.   3.   2.   6.9  5.9  7.   4.   5.2  4.   3.   5.6  6.\n",
      "  3.   5.   2.   6.7  6.   4.2  2.   6.8  6.3  2.   4.   4.8  2.9  4.   6.8\n",
      "  3.   4.   6.5  2.   7.   3.   6.   3.   3.   6.1  2.   2.   3.   6.   3.\n",
      "  3.   5.1  4.   3.   3.   7.   5.   5.2  5.1  6.   4.8  3.   6.7  6.2  3.\n",
      "  6.   5.2  6.8  2.   5.   5.6  5.   5.5  6.   5.6  2.   5.   6.   5.1  5.8\n",
      "  3.   6.   6.   4.   2.   4.   3.9  2.   4.   2.   5.   2.   7.   7.   3.\n",
      "  3.   3.   5.   7.   4.   2.   6.7  3.   3.   5.1  3.   2.9  2.   2.   6.\n",
      "  3.   2.   5.   2.   5.   6.   5.   7.   5.2  5.   6.   3.1  6.2  3.   6.\n",
      "  3.   3.   2.   3.   2.   7.   6.3  4.   7.   3.   2.   2.   2.   4.8  7.\n",
      "  3.   5.   5.1  6.6  2.   5.7  6.5  3.   5.7  5.9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.10468000000000001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, Y_train)\n",
    "# preds = np.rint(rfr.predict(X_test))\n",
    "preds = rfr.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "print(preds)\n",
    "mse(preds, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.032"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How does this compare with randomly shuffled data?\n",
    "mse(permutation(Y_test), Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(7, 5.9000000000000004),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (7, 5.9000000000000004),\n",
       " (4, 4.0),\n",
       " (5, 5.0),\n",
       " (6, 6.2000000000000002),\n",
       " (2, 2.0),\n",
       " (6, 6.0999999999999996),\n",
       " (3, 3.0),\n",
       " (7, 5.4000000000000004),\n",
       " (6, 6.0),\n",
       " (3, 2.8999999999999999),\n",
       " (7, 6.9000000000000004),\n",
       " (2, 2.0),\n",
       " (6, 5.2999999999999998),\n",
       " (3, 3.0),\n",
       " (7, 7.0),\n",
       " (7, 7.0),\n",
       " (4, 4.0),\n",
       " (2, 2.0),\n",
       " (2, 2.0),\n",
       " (7, 6.5999999999999996),\n",
       " (4, 4.0),\n",
       " (2, 2.0),\n",
       " (5, 5.0),\n",
       " (2, 2.0),\n",
       " (2, 2.0),\n",
       " (5, 4.5999999999999996),\n",
       " (7, 7.0),\n",
       " (3, 3.0),\n",
       " (5, 5.0),\n",
       " (5, 5.2000000000000002),\n",
       " (4, 3.8999999999999999),\n",
       " (5, 5.0999999999999996),\n",
       " (7, 6.5999999999999996),\n",
       " (7, 7.0),\n",
       " (2, 2.0),\n",
       " (3, 3.0),\n",
       " (7, 7.0),\n",
       " (7, 6.5999999999999996),\n",
       " (5, 5.0),\n",
       " (6, 5.5999999999999996),\n",
       " (6, 6.0),\n",
       " (6, 5.9000000000000004),\n",
       " (6, 6.4000000000000004),\n",
       " (4, 4.0999999999999996),\n",
       " (6, 6.0),\n",
       " (7, 6.7000000000000002),\n",
       " (4, 4.0),\n",
       " (2, 2.0),\n",
       " (2, 2.0),\n",
       " (6, 6.0),\n",
       " (7, 6.5),\n",
       " (7, 7.0),\n",
       " (5, 5.2999999999999998),\n",
       " (7, 7.0),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (4, 4.0),\n",
       " (5, 5.0),\n",
       " (6, 6.0),\n",
       " (6, 6.0),\n",
       " (3, 3.0),\n",
       " (5, 5.0),\n",
       " (5, 5.2000000000000002),\n",
       " (3, 3.0),\n",
       " (4, 4.0),\n",
       " (5, 5.0999999999999996),\n",
       " (3, 3.1000000000000001),\n",
       " (3, 3.0),\n",
       " (4, 3.1000000000000001),\n",
       " (2, 2.0),\n",
       " (7, 6.9000000000000004),\n",
       " (4, 4.2000000000000002),\n",
       " (3, 3.0),\n",
       " (5, 5.2000000000000002),\n",
       " (7, 6.7000000000000002),\n",
       " (5, 5.0),\n",
       " (6, 6.0),\n",
       " (7, 6.2999999999999998),\n",
       " (2, 2.0),\n",
       " (3, 3.0),\n",
       " (4, 4.0),\n",
       " (4, 4.0),\n",
       " (5, 5.0),\n",
       " (7, 7.0),\n",
       " (7, 5.7999999999999998),\n",
       " (4, 4.0),\n",
       " (3, 3.0),\n",
       " (6, 6.9000000000000004),\n",
       " (3, 2.8999999999999999),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (5, 5.0),\n",
       " (5, 5.0),\n",
       " (7, 6.9000000000000004),\n",
       " (2, 2.0),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (4, 4.0),\n",
       " (5, 5.2000000000000002),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (4, 4.0),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (6, 6.9000000000000004),\n",
       " (6, 5.9000000000000004),\n",
       " (7, 7.0),\n",
       " (4, 4.0),\n",
       " (5, 5.2000000000000002),\n",
       " (4, 4.0),\n",
       " (3, 3.0),\n",
       " (6, 5.5999999999999996),\n",
       " (6, 6.0),\n",
       " (3, 3.0),\n",
       " (6, 5.0),\n",
       " (2, 2.0),\n",
       " (7, 6.7000000000000002),\n",
       " (7, 6.0),\n",
       " (4, 4.2000000000000002),\n",
       " (2, 2.0),\n",
       " (6, 6.7999999999999998),\n",
       " (7, 6.2999999999999998),\n",
       " (2, 2.0),\n",
       " (4, 4.0),\n",
       " (4, 4.7999999999999998),\n",
       " (3, 2.8999999999999999),\n",
       " (4, 4.0),\n",
       " (6, 6.7999999999999998),\n",
       " (3, 3.0),\n",
       " (4, 4.0),\n",
       " (6, 6.5),\n",
       " (2, 2.0),\n",
       " (7, 7.0),\n",
       " (3, 3.0),\n",
       " (6, 6.0),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (6, 6.0999999999999996),\n",
       " (2, 2.0),\n",
       " (2, 2.0),\n",
       " (3, 3.0),\n",
       " (6, 6.0),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (5, 5.0999999999999996),\n",
       " (4, 4.0),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (7, 7.0),\n",
       " (5, 5.0),\n",
       " (5, 5.2000000000000002),\n",
       " (5, 5.0999999999999996),\n",
       " (6, 6.0),\n",
       " (5, 4.7999999999999998),\n",
       " (3, 3.0),\n",
       " (7, 6.7000000000000002),\n",
       " (7, 6.2000000000000002),\n",
       " (3, 3.0),\n",
       " (6, 6.0),\n",
       " (5, 5.2000000000000002),\n",
       " (7, 6.7999999999999998),\n",
       " (2, 2.0),\n",
       " (5, 5.0),\n",
       " (7, 5.5999999999999996),\n",
       " (5, 5.0),\n",
       " (5, 5.5),\n",
       " (6, 6.0),\n",
       " (5, 5.5999999999999996),\n",
       " (2, 2.0),\n",
       " (5, 5.0),\n",
       " (6, 6.0),\n",
       " (5, 5.0999999999999996),\n",
       " (7, 5.7999999999999998),\n",
       " (3, 3.0),\n",
       " (6, 6.0),\n",
       " (6, 6.0),\n",
       " (4, 4.0),\n",
       " (2, 2.0),\n",
       " (4, 4.0),\n",
       " (3, 3.8999999999999999),\n",
       " (2, 2.0),\n",
       " (4, 4.0),\n",
       " (2, 2.0),\n",
       " (5, 5.0),\n",
       " (2, 2.0),\n",
       " (7, 7.0),\n",
       " (7, 7.0),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (5, 5.0),\n",
       " (7, 7.0),\n",
       " (4, 4.0),\n",
       " (2, 2.0),\n",
       " (7, 6.7000000000000002),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (5, 5.0999999999999996),\n",
       " (3, 3.0),\n",
       " (3, 2.8999999999999999),\n",
       " (2, 2.0),\n",
       " (2, 2.0),\n",
       " (5, 6.0),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (5, 5.0),\n",
       " (2, 2.0),\n",
       " (5, 5.0),\n",
       " (6, 6.0),\n",
       " (5, 5.0),\n",
       " (7, 7.0),\n",
       " (5, 5.2000000000000002),\n",
       " (5, 5.0),\n",
       " (6, 6.0),\n",
       " (3, 3.1000000000000001),\n",
       " (6, 6.2000000000000002),\n",
       " (3, 3.0),\n",
       " (6, 6.0),\n",
       " (3, 3.0),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (7, 7.0),\n",
       " (7, 6.2999999999999998),\n",
       " (4, 4.0),\n",
       " (7, 7.0),\n",
       " (3, 3.0),\n",
       " (2, 2.0),\n",
       " (2, 2.0),\n",
       " (2, 2.0),\n",
       " (5, 4.7999999999999998),\n",
       " (7, 7.0),\n",
       " (3, 3.0),\n",
       " (5, 5.0),\n",
       " (5, 5.0999999999999996),\n",
       " (6, 6.5999999999999996),\n",
       " (2, 2.0),\n",
       " (6, 5.7000000000000002),\n",
       " (6, 6.5),\n",
       " (3, 3.0),\n",
       " (6, 5.7000000000000002),\n",
       " (7, 5.9000000000000004)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i for i in zip(Y_test, preds)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization with Autograd\n",
    "\n",
    "Here, I try using autograd to do the optimizations required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.57630778]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict(wb_vect, wb_unflattener, graph_fp):#, linweights):\n",
    "    \"\"\"\n",
    "    Given the weights and biases for each layer, make a prediction for the graph.\n",
    "    \"\"\"\n",
    "    fp = graph_fp.compute_fingerprint(wb_vect, wb_unflattener)\n",
    "    wb = wb_unflattener(wb_vect)\n",
    "    top_layer = max(wb.keys())\n",
    "    linweights = wb[top_layer]['linweights']\n",
    "    return np.dot(fp, linweights)\n",
    "\n",
    "predict(wb.vect, wb.unflattener, gfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.46031647]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@jit\n",
    "def train_loss(wb_vect, wb_unflattener):\n",
    "    \"\"\"\n",
    "    Training loss function - should take in a vector.\n",
    "    \"\"\"\n",
    "    sum_loss = 0\n",
    "    for i, g in enumerate(syngraphs):\n",
    "        gfp = GraphFingerprint(g, 2, shapes)\n",
    "        pred = predict(wb_vect, wb_unflattener, gfp)\n",
    "        loss = len(g.nodes()) - predict(wb_vect, wb_unflattener, gfp)\n",
    "        sum_loss = sum_loss + loss ** 2\n",
    "    \n",
    "    return sum_loss / len(syngraphs)\n",
    "\n",
    "train_loss(wb.vect, wb.unflattener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sgd(grad, wb_vect, wb_unflattener, callback=None, num_iters=200, step_size=0.1, mass=0.9):\n",
    "    \"\"\"\n",
    "    Stochastic gradient descent with momentum.\n",
    "    \"\"\"\n",
    "    velocity = np.zeros(len(wb_vect))\n",
    "    for i in range(num_iters):\n",
    "        print(i)\n",
    "        g = grad(wb_vect, wb_unflattener)\n",
    "        # if callback: callback(x, i, g)\n",
    "        velocity = mass * velocity - (1.0 - mass) * g\n",
    "        wb_vect += step_size * velocity\n",
    "        print(train_loss(wb_vect, wb_unflattener))\n",
    "    return wb_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 18.46031647]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loss(wb.vect, wb.unflattener)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_func = grad(train_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[ 0.69018149]]\n",
      "1\n",
      "[[ 0.68951395]]\n",
      "2\n",
      "[[ 0.68859367]]\n",
      "3\n",
      "[[ 0.68747845]]\n",
      "4\n",
      "[[ 0.68622442]]\n",
      "5\n",
      "[[ 0.68488338]]\n",
      "6\n",
      "[[ 0.68350076]]\n",
      "7\n",
      "[[ 0.68211447]]\n",
      "8\n",
      "[[ 0.68075421]]\n",
      "9\n",
      "[[ 0.6794415]]\n",
      "10\n",
      "[[ 0.67819007]]\n",
      "11\n",
      "[[ 0.67700668]]\n",
      "12\n",
      "[[ 0.67589212]]\n",
      "13\n",
      "[[ 0.67484237]]\n",
      "14\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/Users/ericmjl/anaconda/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1264\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1265\u001b[0;31m         \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1266\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-c2e645b70d89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflattener\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-171b15cc5a04>\u001b[0m in \u001b[0;36msgd\u001b[0;34m(grad, wb_vect, wb_unflattener, callback, num_iters, step_size, mass)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwb_vect\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwb_unflattener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;31m# if callback: callback(x, i, g)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mvelocity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmass\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvelocity\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmass\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ericmjl/Documents/github/autograd/autograd/core.py\u001b[0m in \u001b[0;36mgradfun\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mattach_name_and_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Gradient'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgradfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mforward_pass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0margnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgradfun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ericmjl/Documents/github/autograd/autograd/core.py\u001b[0m in \u001b[0;36mbackward_pass\u001b[0;34m(start_node, end_node, tape)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;34m\"Types are {0} and {1}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_outgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mgradfun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_grad_ops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mog\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast_to_node_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_outgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mog\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcur_outgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ericmjl/Documents/github/autograd/autograd/numpy/numpy_grads.py\u001b[0m in \u001b[0;36mgradfun\u001b[0;34m(g)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mY_axes_ignored\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mY_axes_summed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensordot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mg_axes_from_Y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_axes_ignored\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0msorted_axes_pairs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_axes_summed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_axes_summed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m         forward_permutation = ([i for i in range(anp.ndim(X)) if i not in X_axes_summed]\n",
      "\u001b[0;32m/Users/ericmjl/Documents/github/autograd/autograd/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m                         \u001b[0mtapes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ericmjl/anaconda/lib/python3.5/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mtensordot\u001b[0;34m(a, b, axes)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m         \u001b[0maxes_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1268\u001b[0m         \u001b[0maxes_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
     ]
    }
   ],
   "source": [
    "sgd(grad_func, wb.vect, wb.unflattener, num_iters=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trained_weights = wb.unflattener(wb.vect)[2]['linweights']\n",
    "trained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gfp = GraphFingerprint(syngraphs[0], 2, shapes)\n",
    "gfp.layers[0].nodes(data=True)[4][1]['features'] @ trained_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_graphs = make_synthetic_graphs(100, node_features)\n",
    "\n",
    "test_fingerprints = np.zeros((len(test_graphs), 10))\n",
    "# test_fingerprints\n",
    "for i, g in enumerate(test_graphs):\n",
    "    gfp = GraphFingerprint(g, 2, shapes)\n",
    "    fp = gfp.compute_fingerprint(wb.vect, wb.unflattener)\n",
    "    test_fingerprints[i] = fp\n",
    "\n",
    "# test_fingerprints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "preds = []\n",
    "for i, g in enumerate(test_graphs):\n",
    "    gfp = GraphFingerprint(g, 2, shapes)\n",
    "#     fp = gfp.compute_fingerprint(wb.vect, wb.unflattener)\n",
    "    preds.append(predict(wb.vect, wb.unflattener, gfp)[0])\n",
    "# preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(5, array([ 5.00303973])),\n",
       " (2, array([ 4.21978438])),\n",
       " (3, array([ 4.73538044])),\n",
       " (5, array([ 5.19453785])),\n",
       " (2, array([ 5.19341974])),\n",
       " (6, array([ 5.41108512])),\n",
       " (6, array([ 5.84051064])),\n",
       " (3, array([ 5.77599583])),\n",
       " (2, array([ 2.52383006])),\n",
       " (4, array([ 5.20779674])),\n",
       " (4, array([ 4.70890314])),\n",
       " (5, array([ 5.73078582])),\n",
       " (6, array([ 2.54403173])),\n",
       " (4, array([ 4.06355651])),\n",
       " (5, array([ 5.41559779])),\n",
       " (5, array([ 4.21306957])),\n",
       " (3, array([ 2.58145359])),\n",
       " (6, array([ 2.57563647])),\n",
       " (2, array([ 4.25690491])),\n",
       " (5, array([ 5.83894758])),\n",
       " (4, array([ 3.05971026])),\n",
       " (4, array([ 5.77488627])),\n",
       " (7, array([ 5.84094605])),\n",
       " (6, array([ 5.20779674])),\n",
       " (3, array([ 4.5804738])),\n",
       " (7, array([ 2.53785793])),\n",
       " (6, array([ 5.11027739])),\n",
       " (2, array([ 3.64983927])),\n",
       " (3, array([ 3.64681621])),\n",
       " (2, array([ 5.51839126])),\n",
       " (6, array([ 4.37628934])),\n",
       " (2, array([ 5.60817102])),\n",
       " (7, array([ 5.84094605])),\n",
       " (4, array([ 5.00505932])),\n",
       " (4, array([ 5.60817102])),\n",
       " (3, array([ 5.19589114])),\n",
       " (4, array([ 5.18550751])),\n",
       " (5, array([ 4.77674564])),\n",
       " (7, array([ 3.76475343])),\n",
       " (4, array([ 5.77599583])),\n",
       " (7, array([ 3.10004887])),\n",
       " (5, array([ 5.77431746])),\n",
       " (2, array([ 3.64681621])),\n",
       " (3, array([ 5.00965855])),\n",
       " (5, array([ 5.84094605])),\n",
       " (7, array([ 3.6853702])),\n",
       " (5, array([ 5.20779674])),\n",
       " (7, array([ 5.77470275])),\n",
       " (2, array([ 3.71823596])),\n",
       " (4, array([ 3.07579641])),\n",
       " (7, array([ 3.68432958])),\n",
       " (2, array([ 3.73425545])),\n",
       " (3, array([ 5.77599583])),\n",
       " (5, array([ 4.71278086])),\n",
       " (4, array([ 2.53647459])),\n",
       " (6, array([ 3.05032392])),\n",
       " (7, array([ 4.3736186])),\n",
       " (7, array([ 5.60817102])),\n",
       " (3, array([ 4.29918228])),\n",
       " (4, array([ 5.6016183])),\n",
       " (5, array([ 5.82884715])),\n",
       " (3, array([ 5.77599583])),\n",
       " (4, array([ 5.50966616])),\n",
       " (6, array([ 2.53647459])),\n",
       " (5, array([ 5.8399164])),\n",
       " (3, array([ 5.77383436])),\n",
       " (6, array([ 5.20779674])),\n",
       " (6, array([ 5.60227977])),\n",
       " (4, array([ 5.77525628])),\n",
       " (4, array([ 4.82658718])),\n",
       " (6, array([ 5.51693258])),\n",
       " (2, array([ 5.59445004])),\n",
       " (2, array([ 3.77649476])),\n",
       " (6, array([ 4.28204312])),\n",
       " (2, array([ 5.77599583])),\n",
       " (2, array([ 5.42170945])),\n",
       " (7, array([ 5.77599583])),\n",
       " (6, array([ 3.64862099])),\n",
       " (2, array([ 5.49669616])),\n",
       " (6, array([ 4.25735564])),\n",
       " (6, array([ 5.6039871])),\n",
       " (2, array([ 5.50202482])),\n",
       " (2, array([ 5.60129851])),\n",
       " (4, array([ 5.60817102])),\n",
       " (6, array([ 5.20779674])),\n",
       " (6, array([ 5.18555201])),\n",
       " (2, array([ 2.5266666])),\n",
       " (4, array([ 5.60817102])),\n",
       " (3, array([ 3.74132675])),\n",
       " (6, array([ 5.60817102])),\n",
       " (2, array([ 5.6058484])),\n",
       " (6, array([ 5.7325169])),\n",
       " (4, array([ 4.37535754])),\n",
       " (2, array([ 5.60817102])),\n",
       " (3, array([ 5.19575627])),\n",
       " (2, array([ 3.09994571])),\n",
       " (6, array([ 3.77227574])),\n",
       " (7, array([ 4.37628934])),\n",
       " (4, array([ 5.77599583])),\n",
       " (4, array([ 3.76529161]))]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test = [len(g) for g in syngraphs]\n",
    "\n",
    "[i for i in zip(Y_test, preds)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(preds, n_nodes, alpha=0.3)\n",
    "plt.xlabel('predictions')\n",
    "plt.ylabel('actual')\n",
    "plt.title('number of nodes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Class(object):\n",
    "    \"\"\"docstring for ClassName\"\"\"\n",
    "    def __init__(self, arg):\n",
    "        super(Class, self).__init__()\n",
    "        self.arg = arg\n",
    "        \n",
    "    def __iter__():\n",
    "        pass\n",
    "        \n",
    "    def function(self, value, other_thing):\n",
    "        return value['k']['v']['x'] ** 2 + value['y'] ** 3\n",
    "    \n",
    "    def function2(self, value):\n",
    "        return np.sum(np.dot(value['arr1'], value['arr2'])) + 1\n",
    "        \n",
    "        \n",
    "# def function(value):\n",
    "#     return value ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = Class(np.random.random((10,10)))\n",
    "\n",
    "from collections import OrderedDict\n",
    "value = dict({'k':{'v':{'x':3.0}}, 'y':2.0})\n",
    "gradfunc = grad(c.function)\n",
    "gradfunc(value, 'string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fun2(value):\n",
    "    return np.sum(np.dot(value['arr1'], value['arr2']))\n",
    "\n",
    "value = {'arr1':np.random.random((10,10)), 'arr2':np.random.random((10,10))}\n",
    "gradfunc = grad(fun2)(value)\n",
    "gradfunc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "value = {'arr1':np.random.random((10,10)), 'arr2':np.random.random((10,10))}\n",
    "# value\n",
    "gradfunc = grad(c.function2)\n",
    "gradfunc(value)\n",
    "# np.dot(c.arg, value['arr1'])# , c.arg)\n",
    "# c.function2(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.dot(value['arr1'], value['arr2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
